{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110c974b-fad7-4e9c-8087-58f5c72fd3e3",
   "metadata": {},
   "source": [
    "# Custom deploy Model End-point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee52de-cc7b-4a6d-8b6b-6a647eb96c73",
   "metadata": {},
   "source": [
    "## 1. Project Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba493a63-6a02-4b7e-bb49-1247104ae496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "\n",
    "ENDPOINT_ID = os.getenv(\"ENDPOINT_CONFIG_ID\") # Identificador unico\n",
    "ENDPOINT_COMPANY = os.getenv(\"ENDPOINT_CONFIG_COMPANY\", \"Cinemas\") # Nombre de la compañia\n",
    "ENDPOINT_COMPANY_ABBR = os.getenv(\"ENDPOINT_CONFIG_COMPANY_ABBR\", \"Ci\") # Abreviatura de la compañia\n",
    "\n",
    "ENDPOINT_DISPLAY_NAME = os.getenv(\"ENDPOINT_DISPLAY_NAME\", \"ENDPOINTSent\")\n",
    "ENDPOINT_DESCRIPTION = os.getenv(\"ENDPOINT_DESCRIPTION\", \"Vertex Module Proyect\")\n",
    "\n",
    "ENDPOINT_SERVICE_ACCOUNT = os.getenv(\"ENDPOINT_SERVICE_ACCOUNT\") # Cuenta de Servicio que se asignara al ENDPOINT\n",
    "ENDPOINT_PROJECT_ID = os.getenv(\"ENDPOINT_PROJECT_ID\", \"ProjectVertexAI\") # Proyecto GCP donde se ejecuta el ENDPOINT\n",
    "ENDPOINT_REGION = os.getenv(\"ENDPOINT_REGION\", \"us-central1\") # Region\n",
    "ENDPOINT_BUCKET = os.getenv(\"ENDPOINT_BUCKET\", \"proyect-vertex-ai\") # Bucket donde se guardaran artefactos del despliegue\n",
    "\n",
    "ENDPOINT_PATH_ROOT = os.getenv(\"ENDPOINT_PATH_ROOT\", \"endpoint\")\n",
    "ENDPOINT_MODEL_PATH_ROOT = os.getenv(\"ENDPOINT_MODEL_PATH_ROOT\", \"endpoint/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d04898-08df-41fc-a4ac-9f351ccb4afe",
   "metadata": {},
   "source": [
    "## 2. Endpoint Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9e0371-0dec-456b-b4e0-be18aca77745",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID          = ENDPOINT_PROJECT_ID\n",
    "REGION              = ENDPOINT_REGION\n",
    "#BUCKET_NAME         = \"gs://\" + ENDPOINT_BUCKET \n",
    "BUCKET_NAME         = ENDPOINT_BUCKET\n",
    "MODEL_NAME          = 'Sentiment_Analysis.h5'\n",
    "SAVED_MODEL_DIR    = 'saved_model'\n",
    "SERVICE_ACCOUNT     = ENDPOINT_SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae575844-8001-4da9-a529-358b4e0a088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint/model/saved_model\n"
     ]
    }
   ],
   "source": [
    "#ENDPOINT_ROOT = os.path.join(BUCKET_NAME, ENDPOINT_PATH_ROOT)\n",
    "ENDPOINT_MODEL_ROOT = os.path.join(ENDPOINT_MODEL_PATH_ROOT, MODEL_NAME)\n",
    "ENDPOINT_SAVED_MODEL_ROOT = os.path.join(ENDPOINT_MODEL_PATH_ROOT, SAVED_MODEL_DIR)\n",
    "#print(ENDPOINT_ROOT)\n",
    "print(ENDPOINT_SAVED_MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22d2a0-4237-4f78-9649-37d8e5b97b50",
   "metadata": {},
   "source": [
    "## 3. Instalar TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ceb9b05-b503-4b7d-9ab7-c7afcc566e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af57fe62-e9ca-4dd8-8893-ecc2a6e2a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 04:30:37.696781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-10 04:30:37.696861: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-10 04:30:37.702485: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-10 04:30:38.200909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325f9f5-8a48-4fc5-b8fa-d5505fd2aefd",
   "metadata": {},
   "source": [
    "## 4. Crear y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43325107-288e-4638-a788-05b975bc6a62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "313/313 [==============================] - 279s 883ms/step - loss: 0.4775 - accuracy: 0.7646 - val_loss: 0.3464 - val_accuracy: 0.8548\n",
      "Epoch 2/3\n",
      "313/313 [==============================] - 289s 923ms/step - loss: 0.3007 - accuracy: 0.8767 - val_loss: 0.3604 - val_accuracy: 0.8420\n",
      "Epoch 3/3\n",
      "313/313 [==============================] - 270s 863ms/step - loss: 0.2353 - accuracy: 0.9072 - val_loss: 0.3569 - val_accuracy: 0.8608\n",
      "782/782 [==============================] - 163s 208ms/step - loss: 0.3679 - accuracy: 0.8563\n",
      "Pérdida del modelo: 0.3679\n",
      "Precisión del modelo: 85.63%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Parámetros del modelo\n",
    "max_features = 5000  # Número máximo de palabras a considerar como características\n",
    "max_len = 200  # Longitud máxima de la secuencia de texto\n",
    "embedding_dim = 128  # Dimensión de los vectores de palabra de la capa Embedding\n",
    "\n",
    "# Cargar el conjunto de datos IMDB\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(units=256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Pérdida del modelo: {loss:.4f}\")\n",
    "print(f\"Precisión del modelo: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a4e29d-d1d0-46ef-b9ee-e2c4e445a319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 128)          640000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               394240    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1034497 (3.95 MB)\n",
      "Trainable params: 1034497 (3.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('Sentiment_Analysis.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515458a-47fe-4907-bd47-e230dfcbac3b",
   "metadata": {},
   "source": [
    "## 5. Crear Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e9559-2425-4231-80c0-43b9979962c4",
   "metadata": {},
   "source": [
    "### 5.1 Exportar a saved_model (artefacto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7bd6f2-8800-4d4e-8cbc-949823721955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Exportar el modelo a saved_model\n",
    "tf.saved_model.save(model, './saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b1388-5a5e-4de2-83cb-fb83eee5fca5",
   "metadata": {},
   "source": [
    "### 5.2  Subir el model.h5 y saved_model a GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762cf372-0624-4812-8bb0-1ae2f65ff759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_gcs(bucket_name, local_file_path, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "\n",
    "# Especifica el nombre del bucket de GCS y los nombres de archivo\n",
    "bucket_name = BUCKET_NAME#ENDPOINT_MODEL_ROOT#'nombre_del_bucket'\n",
    "local_file_path = MODEL_NAME\n",
    "destination_blob_name = ENDPOINT_MODEL_ROOT\n",
    "\n",
    "# Sube el archivo al bucket de GCS\n",
    "upload_to_gcs(bucket_name, local_file_path, destination_blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48b8445-126c-4156-934b-1e8976ae106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subido: saved_model/fingerprint.pb -> gs://proyect-vertex-ai/endpoint/model/saved_model/fingerprint.pb\n",
      "Subido: saved_model/saved_model.pb -> gs://proyect-vertex-ai/endpoint/model/saved_model/saved_model.pb\n",
      "Subido: saved_model/variables/variables.index -> gs://proyect-vertex-ai/endpoint/model/saved_model/variables/variables.index\n",
      "Subido: saved_model/variables/variables.data-00000-of-00001 -> gs://proyect-vertex-ai/endpoint/model/saved_model/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "def upload_directory_to_gcs(bucket_name, local_directory, destination_directory):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(destination_directory, os.path.relpath(local_path, local_directory))\n",
    "            blob = bucket.blob(destination_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "            print(f'Subido: {local_path} -> gs://{bucket_name}/{destination_path}')\n",
    "\n",
    "# Especifica el nombre del bucket de GCS y los directorios local y de destino\n",
    "bucket_name = BUCKET_NAME\n",
    "local_directory = SAVED_MODEL_DIR\n",
    "destination_directory = ENDPOINT_SAVED_MODEL_ROOT\n",
    "\n",
    "# Sube el directorio al bucket de GCS\n",
    "upload_directory_to_gcs(bucket_name, local_directory, destination_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0d8e4-c303-432a-8f3f-d832c2478499",
   "metadata": {},
   "source": [
    "### 5.3 Subir modelo a registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e849ab-de5c-481b-9e58-ce17c0afbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.34.0)\n",
      "Requirement already satisfied: shapely<2 in /opt/conda/lib/python3.10/site-packages (1.8.5.post1)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.10.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.22.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.57.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.16)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-cloud-aiplatform \"shapely<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f059c570-66f4-420a-9d6b-449d7ca791f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from typing import Optional\n",
    "\n",
    "def upload_model_sample(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    serving_container_image_uri: str,\n",
    "    artifact_uri: Optional[str] = None\n",
    "):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "    \n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "    )\n",
    "    \n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab9669d-55a9-4703-85d2-68baac741f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://proyect-vertex-ai/endpoint/model/saved_model\n"
     ]
    }
   ],
   "source": [
    "#BUCKET_NAME         = \"gs://\" + ENDPOINT_BUCKET \n",
    "ARTIFACT_URI           = \"gs://\" + os.path.join(ENDPOINT_BUCKET, destination_directory)\n",
    "print(ARTIFACT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecdc704-a209-4fe3-8225-66191c4f846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/297594721003/locations/us-central1/models/4255433255911686144/operations/5884005346120302592\n",
      "Model created. Resource name: projects/297594721003/locations/us-central1/models/4255433255911686144@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/297594721003/locations/us-central1/models/4255433255911686144@1')\n",
      "proyect_vertex\n",
      "projects/297594721003/locations/us-central1/models/4255433255911686144\n"
     ]
    }
   ],
   "source": [
    "#upload_model_sample(project= PROJECT_ID, location = REGION, display_name= 'keras_registry', serving_container_image_uri = destination_directory, artifact_uri = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest')\n",
    "#'gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-5:latest'\n",
    "keras_model_registry = upload_model_sample(project= \"projectvertexai-401304\", \\\n",
    "                    location = REGION, \\\n",
    "                    display_name= 'proyect_vertex', \\\n",
    "                    serving_container_image_uri = 'gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-5:latest', \\\n",
    "                    artifact_uri = ARTIFACT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4710e90a-7736-41d0-a0e4-59a4ad65a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model_registry = keras_model_registry.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde0e617-2e46-4bd7-8cf9-d6485b1e060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255433255911686144\n"
     ]
    }
   ],
   "source": [
    "print(name_model_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e1b79-fe85-4bf9-b256-2f1ff3c0c141",
   "metadata": {},
   "source": [
    "### 5.4 Creación del Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20384ae6-1510-4f4b-9b37-37b22c6f7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint_sample(\n",
    "    project: str,\n",
    "    display_name: str,\n",
    "    location: str,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name,\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    print(endpoint.display_name)\n",
    "    print(endpoint.resource_name)\n",
    "    return endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5494abd-9d48-4566-a26e-5a83ada99ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/297594721003/locations/us-central1/endpoints/1853391775360614400/operations/7370193223152566272\n",
      "Endpoint created. Resource name: projects/297594721003/locations/us-central1/endpoints/1853391775360614400\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/297594721003/locations/us-central1/endpoints/1853391775360614400')\n",
      "Sentiment_Analysis_endpoint\n",
      "projects/297594721003/locations/us-central1/endpoints/1853391775360614400\n"
     ]
    }
   ],
   "source": [
    "endpoint = create_endpoint_sample(project= \"projectvertexai-401304\", \\\n",
    "                                    display_name= 'Sentiment_Analysis_endpoint', \\\n",
    "                                    location= REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d34bf63-178b-4f6d-9b17-2f139f332524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "ENDPOINT_ID          DISPLAY_NAME\n",
      "1853391775360614400  Sentiment_Analysis_endpoint\n",
      "1941211968094339072  Sentiment_Analysis_endpoint\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_NAME = 'Sentiment_Analysis_endpoint'\n",
    "!gcloud ai endpoints list \\\n",
    "  --region=$REGION\\\n",
    "  --filter=display_name=$ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355ff9f-d155-4ef7-9c2d-928a1894b206",
   "metadata": {},
   "source": [
    "### 5.5 Deploy Model to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cd10c2d-3640-4ed9-b63e-4734f3600188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/conda/lib/python3.10/site-packages (0.42.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from shap) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from shap) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap) (1.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from shap) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.10/site-packages (from shap) (4.66.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap) (23.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap) (0.57.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap) (0.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ecd40b-28e7-4c98-bfc0-718bc4d8eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Sequence, Tuple\n",
    "#import shap.explain\n",
    "\n",
    "def deploy_model_with_dedicated_resources_sample(\n",
    "    project,\n",
    "    location,\n",
    "    model_name: str,\n",
    "    machine_type: str,\n",
    "    endpoint: Optional[aiplatform.Endpoint] = None,\n",
    "    deployed_model_display_name: Optional[str] = None,\n",
    "    traffic_percentage: Optional[int] = 0,\n",
    "    traffic_split: Optional[Dict[str, int]] = None,\n",
    "    min_replica_count: int = 1,\n",
    "    max_replica_count: int = 1,\n",
    "    accelerator_type: Optional[str] = None,\n",
    "    accelerator_count: Optional[int] = None,\n",
    "    #explanation_metadata: Optional[explain.ExplanationMetadata] = None,\n",
    "    #explanation_parameters: Optional[explain.ExplanationParameters] = None,\n",
    "    metadata: Optional[Sequence[Tuple[str, str]]] = (),\n",
    "    sync: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    model_name: A fully-qualified model resource name or model ID.\n",
    "          Example: \"projects/123/locations/us-central1/models/456\" or\n",
    "          \"456\" when project and location are initialized or passed.\n",
    "    \"\"\"\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "    print('model name: ', model_name)\n",
    "    model = aiplatform.Model(model_name=model_name)\n",
    "    #model = aiplatform.Model(display_name=model_name)\n",
    "    \n",
    "    # The explanation_metadata and explanation_parameters should only be\n",
    "    # provided for a custom trained model and not an AutoML model.\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=deployed_model_display_name,\n",
    "        traffic_percentage=traffic_percentage,\n",
    "        traffic_split=traffic_split,\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        #explanation_metadata=explanation_metadata,\n",
    "        #explanation_parameters=explanation_parameters,\n",
    "        metadata=metadata,\n",
    "        sync=sync,\n",
    "    )\n",
    "    \n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52f0ea37-f99b-4dfd-9565-bde6c278a574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  4255433255911686144\n",
      "Deploying model to Endpoint : projects/297594721003/locations/us-central1/endpoints/1853391775360614400\n",
      "Deploy Endpoint model backing LRO: projects/297594721003/locations/us-central1/endpoints/1853391775360614400/operations/7993941771543379968\n",
      "Endpoint model deployed. Resource name: projects/297594721003/locations/us-central1/endpoints/1853391775360614400\n",
      "proyect_vertex\n",
      "projects/297594721003/locations/us-central1/models/4255433255911686144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7f65a580d840> \n",
       "resource name: projects/297594721003/locations/us-central1/models/4255433255911686144"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_model_with_dedicated_resources_sample(\n",
    "    project=\"projectvertexai-401304\", \\\n",
    "    location=REGION, \\\n",
    "    model_name= name_model_registry, \\\n",
    "    machine_type='n1-standard-4', \\\n",
    "    endpoint= endpoint, \\\n",
    "    deployed_model_display_name='Sentiment_Analysis_model_endpoint', \\\n",
    "    #traffic_percentage: Optional[int] = 0,\n",
    "    #traffic_split: Optional[Dict[str, int]] = None,\n",
    "    min_replica_count= 1, \\\n",
    "    max_replica_count= 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e7866-ca8b-4ca3-9315-f1b5d03e05ad",
   "metadata": {},
   "source": [
    "### 5.6 Obtener una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b130045f-dfb1-4d59-ab7c-2934a150f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_predict_sample(\n",
    "    project: str, location: str, instances: str, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01e4eb1a-6945-4e2a-b3b0-4bfd85c49821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66c663bd-678a-4a8a-82d5-72a8dedc4133",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Parámetros del modelo\n",
    "max_features = 5000  # Número máximo de palabras a considerar como características\n",
    "max_len = 200  # Longitud máxima de la secuencia de texto\n",
    "embedding_dim = 128  # Dimensión de los vectores de palabra de la capa Embedding\n",
    "\n",
    "# Cargar el conjunto de datos IMDB\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5db53ee-1ab3-499c-973b-2fd2c2da23b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos de entrada: \n",
      " Esta película no estuvo mal, pero no me gustó\n"
     ]
    }
   ],
   "source": [
    "input_data = \"Esta película no estuvo mal, pero no me gustó\"\n",
    "print(\"datos de entrada: \\n\", input_data)\n",
    "word_index = imdb.get_word_index()\n",
    "max_len = 200\n",
    "max_features = 5000\n",
    "# Preprocesar la revisión de muestra y convertirla en una secuencia numérica\n",
    "input_data = [word_index[word] if word in word_index and word_index[word] < max_features else 0 for word in input_data.split()]\n",
    "input_data = pad_sequences([input_data], maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7167f77-b7e0-46d8-83e0-c62d6de4be50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data = input_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c0d1af8-613f-4493-9dca-60f9097d7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 54, 69, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ecf0a346-a3af-4a7e-8181-9ed71b793c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(predictions=[[0.415145695]], deployed_model_id='7237946507184308224', model_version_id='1', model_resource_name='projects/297594721003/locations/us-central1/models/4255433255911686144', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "response = endpoint_predict_sample(\n",
    "    project= \"projectvertexai-401304\" ,\\\n",
    "    location= REGION ,\\\n",
    "    instances= input_data ,\\\n",
    "    endpoint= endpoint.name \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558be9a-6382-44bd-961f-3013a045957c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
